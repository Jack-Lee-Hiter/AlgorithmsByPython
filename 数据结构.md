# 数据结构
## 一些概念
> 数据结构就是研究数据的**逻辑结构**和**物理结构**以及它们之间**相互关系**，并对这种结构定义相应的运算，而且确保经过这些运算后所得到的新结构仍然是原来的结构类型。1. 数据：所有能被输入到计算机中，且能被计算机处理的符号的集合。是计算机操作的对象的总称。
2. 数据元素：数据（集合）中的一个“个体”，数据及结构中讨论的**基本**单位
3. 数据项：数据的不可分割的最小单位。一个数据元素可由若干个数据项组成。
4. 数据类型：在一种程序设计语言中，变量所具有的数据种类。整型、浮点型、字符型等等

1. 逻辑结构：数据之间的相互关系。
	* 集合 结构中的数据元素除了同属于一种类型外，别无其它关系。
	* 线性结构 数据元素之间一对一的关系
	* 树形结构 数据元素之间一对多的关系
	* 图状结构或网状结构 结构中的数据元素之间存在多对多的关系
2. 物理结构/存储结构：数据在计算机中的表示。物理结构是描述数据具体在内存中的存储（如：顺序结构、链式结构、索引结构、哈希结构）等

1. 算法五个特性： 有穷性、确定性、可行性、输入、输出
2. 算法设计要求：正确性、可读性、健壮性、高效率与低存储量需求
3. 设计算法在执行时间是需要考虑：算法选用的规模、问题的规模
4. 时间复杂度：算法的执行时间与原操作**执行次数**之和成正比。时间复杂度有小到大：O(1)、O(logn)、O(n)、O(nlogn)、O(n<sup>2</sup>)、O(n<sup>3</sup>)。幂次时间复杂度有小到大O(2<sup>n</sup>)、O(n!)、O(n<sup>n</sup>)
5. 空间复杂度：若输入数据所占空间只取决于问题本身，和算法无关，则只需要分析**除输入和程序之外的辅助变量所占额外空间**。

## 线性表
线性表是一种典型的线性结构。头结点无前驱有一个后继，尾节点无后继有一个前驱。

1. 线性表的顺序存储结构：把线性表的结点按逻辑顺序依次存放在一组地址连续的存储单元里。用这种方法存储的线性表简称顺序表。**数组**。
	* 便于线性表的构造和任意元素的访问
	* 插入：插入新结点，之后结点后移。平均时间复杂度:O(n)
	* 删除：删除节点，之后结点前移。平均时间复杂度:O(n)
2. 线性链表：用一组任意的存储单元来依次存放线性表的结点，这组存储单元即可以是连续的，也可以是不连续的，甚至是零散分布在内存中的任意位置上的。因此，链表中结点的逻辑次序和物理次序不一定相同。为了能正确表示结点间的逻辑关系，在存储每个结点值的同时，还必须存储指示其后继结点的地址。data域是数据域，用来存放结点的值。next是指针域（亦称链域），用来存放结点的直接后继的地址（或位置）。
	* **单链表**中每个结点的存储地址是存放在其前趋结点next域中，而开始结点无前趋，故应设头指针head指向开始结点。同时，由于最后一个结点无后继，故结点的指针域为空，即NULL。头插法建表(逆序)、尾插法建表(顺序)
		* 查找：只能从链表的头指针出发，顺链域next逐个结点往下搜索，直到搜索到第i个结点为止。因此，**链表不是随机存取结构**。
		* 插入：先找到表的第i-1的存储位置，然后插入。新结点先连后继，再连前驱。
		* 删除：首先找到a<sub>i-1</sub>的存储位置p。然后令p–>next指向a<sub>i</sub>的直接后继结点，即把a<sub>i</sub>从链上摘下。最后释放结点a<sub>i</sub>的空间.r=p->next;p->next=r->next;delete r;
	* 静态链表：用一维数组来实现线性链表，这种用一维数组表示的线性链表，称为静态链表。静态：体现在表的容量是一定的。（数组的大小）；链表：插入与删除同前面所述的动态链表方法相同。
	* 静态链表是用数组实现的，是顺序的存储结构，在物理地址上是连续的，而且需要预先分配大小。动态链表是用申请内存函数（C是malloc,C++是new）动态申请内存的，所以在链表的长度上没有限制。动态链表因为是动态申请内存的，所以每个节点的物理地址不连续，要通过指针来顺序访问。静态链表在插入、删除时也是通过修改指针域来实现的，与动态链表没有什么分别
	* 循环链表：是一种头尾相接的链表。其特点是无须增加存储量，仅对表的链接方式稍作改变，即可使得表处理更加方便灵活。
		* 在单链表中，将终端结点的指针域NULL改为指向表头结点的或开始结点，就得到了单链形式的循环链表，并简单称为**单循环链表**。由于循环链表中没有NULL指针，故涉及遍历操作时，其终止条件就不再像非循环链表那样判断p或p—>next是否为空，而是判断它们是否等于某一指定指针，如头指针或尾指针等。
	* 双向链表:在单链表的每个结点里再增加一个指向其直接前趋的指针域prior。这样就形成的链表中有两个方向不同的链。双链表一般由头指针唯一确定的，将头结点和尾结点链接起来构成循环链表，并称之为双向链表。设指针p指向某一结点，则双向链表结构的对称性可用下式描述：p—>prior—>next=p=p—>next—>prior
		* 插入：先搞定插入节点的前驱和后继，再搞定后结点的前驱，最后搞定前结点的后继。## 栈和队列
### 栈
栈(Stack)是限制在表的一端进行插入和删除运算的线性表，通常称插入、删除的这一端为栈顶(Top)，另一端为栈底(Bottom)。先进后出。

1. 顺序存储栈：顺序存储结构
2. 链栈：链式存储结构。插入和删除操作仅限制在链头位置上进行。栈顶指针就是链表的头指针。

应用，[代码](https://github.com/Jack-Lee-Hiter/AlgorithmsByPython/blob/master/Stack.py)：

1. 进制转换2. 括号匹配的检验
3. 行编辑程序
4. 迷宫求解：若当前位置“可通”，则纳入路径，继续前进;若当前位置“不可通”，则后退，换方向继续探索;若四周“均无通路”，则将当前位置从路径中删除出去。
5. 表达式求解：前缀、中缀、后缀。
	* 操作数之间的相对次序不变;
	* 运算符的相对次序不同;
	* 中缀式丢失了括弧信息，致使运算的次序不确定
	* 前缀式的运算规则为:连续出现的两个操作数和在它们之前且紧靠它们的运算符构成一个最小表达式
	* 后缀式的运算规则为:运算符在式中出现的顺序恰为表达式的运算顺序;每个运算符和在它之前出现且紧靠它的两个操作数构成一个最小表达式。
6. 实现递归：多个函数嵌套调用的规则是：后调用先返回。

### 队列
队列(Queue)也是一种运算受限的线性表。它只允许在表的一端进行插入，而在另一端进行删除。允许删除的一端称为队头(front)，允许插入的一端称为队尾(rear)。先进先出。

1. 顺序队列：顺序存储结构。当头尾指针相等时队列为空。在非空队列里，头指针始终指向队头前一个位置，而尾指针始终指向队尾元素的实际位置
2. 循环队列。在循环队列中进行出队、入队操作时，头尾指针仍要加1，朝前移动。只不过当头尾指针指向向量上界（MaxSize-1）时，其加1操作的结果是指向向量的下界0。除非向量空间真的被队列元素全部占用，否则不会上溢。因此，除一些简单的应用外，真正实用的顺序队列是循环队列。故队空和队满时头尾指针均相等。因此，我们无法通过front=rear来判断队列“空”还是“满”
3. 链队列：链式存储结构。限制仅在表头删除和表尾插入的单链表。显然仅有单链表的头指针不便于在表尾做插入操作，为此再增加一个尾指针，指向链表的最后一个结点。

1.队空条件：rear==front，但是一般需要引入新的标记来说明栈满还是栈空，比如每个位置布尔值
2.队满条件：(rear+1) %QueueSIze==front，其中QueueSize为循环队列的最大长度
3.计算队列长度：（rear-front+QueueSize）%QueueSize
4.入队：（rear+1）%QueueSize
5.出队：（front+1）%QueueSize

## 串
串(String)是零个或多个字符组成的有限序列。长度为零的串称为**空串**(Empty String)，它不包含任何字符。通常将仅由一个或多个空格组成的串称为**空白串**(Blank String) 注意：空串和空白串的不同，例如“  ”和“”分别表示长度为1的空白串和长度为0的空串。

串的表示和实现：

1. 定长顺序存储表示。静态存储分配的顺序表。
2. 堆分配存储表示。存储空间是在程序执行过程中动态分配而得。所以也称为动态存储分配的顺序表
3. 串的链式存储结构。

串匹配：将主串称为目标串，子串称之为模式串。蛮力法匹配。[KMP算法](http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html)匹配。[Boyer-Moore算法](https://github.com/Jack-Lee-Hiter/Introduction-to-The-Design-and-Analysis-of-Algorithms/blob/master/Boyer-Moore/BM%20by%20swift)匹配。

## 数组和广义表
数组和广义表可看成是一种特殊的线性表，其特殊在于: 表中的元素本身也是一种线性表。内存连续。根据下标在O(1)时间读/写任何元素。

**二维数组，多维数组，广义表、树、图都属于非线性结构**

### 数组
数组的顺序存储：行优先顺序；列优先顺序。数组中的任一元素可以在相同的时间内存取，即顺序存储的数组是一个随机存取结构。矩阵的压缩：

1. 对称矩阵、三角矩阵：直接存储矩阵的上三角或者下三角元素。**注意区分i>=j和i<j的情况**
2. 对角矩阵：除了主对角线和主对角线相邻两侧的若干条对角线上的元素之外，其余元素皆为零。
3. 稀疏矩阵：非零元素个数远小于矩阵元素总数。
	* 三元组顺序表。三元组顺序表虽然节省了存储空间，但时间复杂度比一般矩阵转置的算法还要复杂，同时还有可能增加算法的难度。因此，此算法仅适用于t<<m*n的情况。
	* 稀疏矩阵在采用压缩存储后将会失去随机存储的功能。因为在这种矩阵中，非零元素的分布是没有规律的，为了压缩存储，就将每一个非零元素的值和它所在的行、列号做为一个结点存放在一起，这样的结点组成的线性表中叫三元组表，它已不是简单的向量，所以无法用下标直接存取矩阵中的元素。
	* 对于用三元组存储稀疏矩阵，每个元素要用行号,列号,元素值来表示,在用三元组表示稀疏矩阵,还要三个成员来记住矩阵的行数列数,总的元素数，即总共需要(非零元素个数)n+1个元素。

### 广义表
广义表（Lists，又称列表）是线性表的推广。广义表是n(n≥0)个元素a1,a2,a3,…,an的有限序列，其中a<sub>i</sub>或者是原子项，或者是一个广义表。若广义表LS（n>=1)非空，则a1是LS的表头，其余元素组成的表(a2,…an)称为LS的表尾。广义表的元素可以是广义表，也可以是原子，广义表的元素也可以为空。

例子：

1. A=（）——A是一个空表，其长度为零。2. B=（e）——表B只有一个原子e，B的长度为1。3. C=（a,(b,c,d))——表C的长度为2，两个元素分别为原子a和子表(b,c,d)。4. D=（A，B，C）——表D的长度为3，三个元素都是广义 表。显然，将子表的值代入后，则有D=(( ),(e),(a,(b,c,d)))。
5. E=（a,E）——这是一个递归的表，它的长度为2，E相当于一个无限的广义表E=(a,(a,(a,(a,…)))).

三个结论：

1. 广义表的元素可以是子表，而子表的元素还可以是子表。由此，广义表是一个多层次的结构，可以用图形象地表示
2. 广义表可为其它表所共享。例如在上述例4中，广义表A，B，C为D的子表，则在D中可以不必列出子表的值，而是通过子表的名称来引用。
3. 广义表的递归性考点：

1. 广义表是0个或多个单因素或子表组成的有限序列，广义表可以是自身的子表，广义表的长度n>=0，所以可以为空表。广义表的**同级**元素(直属于同一个表中的各元素)具有**线性**关系
2. 广义表的表头为空，并不代表该广义表为空表。广义表()和(())不同。前者是长度为0的空表，对其不能做求表头和表尾的运算；而后者是长度为l的非空表(只不过该表中惟一的一个元素是空表)，对其可进行分解，得到的表头和表尾均是空表()
3. 已知广义表LS＝((a,b,c),(d,e,f)),运用head和tail函数取出LS中原子e的运算是head(tail(head(tail(LS)))。根据表头、表尾的定义可知：任何一个非空广义表的表头是表中第一个元素，它可以是原子，也可以是子表，而其**表尾必定是子表**。也就是说，广义表的head操作，取出的元素是什么，那么结果就是什么。但是tail操作取出的元素外必须加一个表——“（）“。tail(LS)＝((d,e,f))；head(tail(LS))=(d,e,f)；tail(head(tail(LS)))=(e,f)；head(tail(head(tail(LS))))=e。
4. 二维以上的数组其实是一种特殊的广义表
5. 在（非空）广义表中：1、表头head可以是原子或者一个表 2、表尾tail一定是一个表 3.广义表难以用顺序存储结构 4.广义表可以是一个多层次的结构

## 树和二叉树
一种**非线性**结构。树是递归结构，在树的定义中又用到了树的概念。

基本术语：

1. 树结点：包含一个数据元素及若干指向子树的分支；2. 孩子结点：结点的子树的根称为该结点的孩子；3. 双亲结点：B结点是A结点的孩子，则A结点是B结点的双亲；4. 兄弟结点：同一双亲的孩子结点；5. 堂兄结点：同一层上结点；6. 结点层次：根结点的层定义为1；根的孩子为第二层结点，依此类推；7. 树的高（深）度：树中最大的结点层8. 结点的度：结点子树的个数9. 树的度： 树中最大的结点度。10. 叶子结点：也叫终端结点，是度为0的结点；11. 分枝结点：度不为0的结点（非终端结点）；12. 森林：互不相交的树集合；13. 有序树：子树有序的树，如：家族树；14. 无序树：不考虑子树的顺序；

### 二叉树
二叉树可以为空。二叉树结点的子树要区分左子树和右子树，即使只有一棵子树也要进行区分，说明它是左子树，还是右子树。这是二叉树与树的最主要的差别。注意区分：二叉树、二叉查找树/二叉排序树/二叉搜索树、二叉平衡(查找)树

**二叉树与树是不同的，二叉树不等价于分支树最多为二的有序树。当一个结点只包含一个子节点时，对于有序树并无左右孩子之分，而对于二叉树来说依然有左右孩子之分，所以二叉树与树是两种不同的结构。**

性质：

1. 在二叉树的第 i 层上至多有2<sup>i-1</sup>个结点。
2. 深度为 k 的二叉树上至多含 2<sup>k</sup>-1 个结点（k≥1）
3. 对任何一棵二叉树，若它含有n<sub>0</sub>个叶子结点、n<sub>2</sub>个度为 2 的结点，则必存在关系式：n<sub>0</sub>= n<sub>2</sub>+1。
4. 具有 n 个结点的完全二叉树的深度为⎣log<sub>2</sub> n⎦+1 。
5. n个结点的二叉树中，完全二叉树具有最小的路径长度。
6. 如果对一棵有n个结点的完全二叉树的结点按层序编号,则对任一结点i（1<=i<=n),有：
	* 如果i＝1，则结点i无双亲，是二叉树的根；如果i>1，则其双亲的编号是 i/2(整除）。
	* 如果2i>n，无左孩子；否则，其左孩子是结点2i。
	* 如果2i＋1>n，则结点i无右孩子；否则，其右孩子是结点2i＋1。

二叉树的存储结构

1. 顺序存储结构：仅仅适用于满或完全二叉树，结点之间的层次关系由性质5确定。
2. 二叉链表法：每个节点存储左子树和右子树。三叉链表：左子树、右子树、父节点

#### **遍历二叉树和线索二叉树**

遍历二叉树：使得每一个结点均被访问一次，而且仅被访问一次。非递归的遍历实现要利用栈。

* 先序遍历DLR：根节点->左子树->右子树
* 中序遍历LDR：左子树->根节点->右子树
* 后续遍历LRD：左子树->右子树->根节点

线索二叉树：对二叉树所有结点做某种处理可在遍历过程中实现；检索（查找）二叉树某个结点，可通过遍历实现；如果能将二叉树线索化，就可以简化遍历算法，提高遍历速度，目的是加快查找结点的前驱或后继的速度。

如何线索化？以中序遍历为例，若能将中序序列中每个结点前趋、后继信息保存起来，以后再遍历二叉树时就可以根据所保存的结点前趋、后继信息对二叉树进行遍历。对于二叉树的线索化，实质上就是遍历一次二叉树，只是在遍历的过程中，检查当前结点左，右指针域是否为空，若为空，将它们改为指向前驱结点或后继结点的线索。**前驱就是在这一点之前走过的点，不是下一将要去往的点**。加上结点前趋后继信息（结索）的二叉树称为**线索二叉树**。n个结点的线索二叉树上每个结点有2个指针域（指向左孩子和右孩子），总共有2n个指针域；一个n个结点的树有n-1条边，那么空指针域= 2n - (n-1) = n + 1，即线索数为n+1。指针域tag为0，存放孩子指针，为1，存放前驱/后继节点指针。

线索树下结点x的前驱与后继查找：设结点x相应的左（右）标志是线索标志，则lchild(rchild)就是前驱(后继），否则：

* LDR--前驱：左子树中最靠右边的结点；后继：右子树中最靠左边的结点
* LRD--前驱：右子树的根，若无右子树，为左子树跟。后继：x是根，后继是空；x是双亲的右孩子、x是双亲的左孩子，但双亲无右孩子，双亲是后继；x是双亲的左孩子，双亲有右孩子，双亲右子树中最左的叶子是后继
* DLR--对称于LRD线索树---将LRD中所有左右互换，前驱与后继互换，得到DLR的方法。
* 为简化线索链表的遍历算法，仿照线性链表，为线索链表加上一头结点，约定：	* 头结点的lchild域：存放线索链表的根结点指针；	* 头结点的rchild域: 中序序列最后一个结点的指针；	* 中序序列第一结点lchild域指向头结点;	* 中序序列最后一个结点的rchild域指向头结点;

中序遍历的线索二叉树以及线索二叉树链表示意图
![xiansuobinarytree](http://images.cnitblog.com/blog/311549/201309/13230006-d365a5866c094ee7b3897a1675d34716.jpg)

一棵左右子树均不空的二叉树在前序线索化后,其中空的链域的个数是1。**前序和后续线索化后空链域个数都是1，中序是2**。二叉树在线索化后，仍不能有效求解的问题是前序求前序先驱，后序求后序后继。

中序遍历的顺序为：左、根、右，所以对于每一非空的线索，左子树结点的后继为根结点，右子树结点的前驱为根结点，再递归的执行上面的过程，可得非空线索均指向其祖先结点。**在中序线索二叉树中,每一非空的线索均指向其祖先结点**。在二叉树上加上结点前趋、后继线索后，可利用线索对二叉树进行遍历,此时，**不需栈，也不需递归**。基本步骤：

1. p=T->lchild; p指向线索链表的根结点；
2. 若线索链表非空，循环：	* 循环，顺着p左孩子指针找到最左下结点；访问之； 	* 若p所指结点的右孩子域为线索，p的右孩子结点即为后继结点循环： p=p->rchild； 并访问p所指结点；（在此循环中，顺着后继线索访问二叉树中的结点）	* 一旦线索“中断”，p所指结点的右孩子域为右孩子指针，p=p->rchild，使 p指向右孩子结点；

### 树和森林
树的存储结构：

1. 双亲表示法
2. 孩子表示法
3. 利用图表示树
4. 孩子兄弟表示法（二叉树表示法）：链表中每个结点的两指针域分别指向其第一个孩子结点和下一个兄弟结点

将树转化成二叉树：右子树一定为空

1. 加线：在兄弟之间加一连线2. 抹线：对每个结点，除了其左孩子外，去除其与其余孩子之间的关系3. 旋转：以树的根结点为轴心，将整树顺时针转45°

森林转换成二叉树：

1. 将各棵树分别转换成二叉树2. 将每棵树的根结点用线相连3. 以第一棵树根结点为二叉树的根

树与转换后的二叉树的关系：转换后的二叉树的先序对应树的先序遍历；转换后的二叉树的中序对应树的后序遍历### 哈弗曼树/霍夫曼树
一些概念

1. 路径：从一个祖先结点到子孙结点之间的分支构成这两个结点间的路径；2. 路径长度：路径上的分支数目称为路径长度；3. 树的路径长度：从根到每个结点的路径长度之和。4. 结点的权：根据应用的需要可以给树的结点赋权值；5. 结点的带权路径长度：从根到该结点的路径长度与该结点权的乘积；6. 树的带权路径长度=树中所有叶子结点的带权路径之和；通常记作  WPL=∑w<sub>i</sub>×l<sub>i</sub> 7. 哈夫曼树：假设有n个权值(w<sub>1</sub>,  w<sub>2</sub>, … , w<sub>n</sub>)，构造有n个叶子结点的二叉树，每个叶子结点有一个 w<sub>i</sub>作为它的权值。则带权路径长度最小的二叉树称为哈夫曼树。前缀码的定义：在一个字符集中，任何一个字符的编码都不是另一个字符编码的前缀。霍夫曼编码就是前缀码，可用于快速判断霍夫曼编码是否正确。霍夫曼树是满二叉树，若有n个节点，则共有(n+1)/2个码子

给定n个权值作为n的叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为霍夫曼树(Huffman Tree)。霍夫曼树是带权路径长度最短的树，权值较大的结点离根较近。

假设哈夫曼树是二叉的话，则度为0的结点个数为N，度为2的结点个数为N-1，则结点总数为2N-1。哈夫曼树的结点个数必为奇数。

哈夫曼树不一定是完全二叉树，但一定是最优二叉树。

### 图遍历与回溯
图搜索->形成搜索树

1. 穷举法。
2. 贪心法。多步决策，每步选择使得构成一个问题的可能解，同时满足目标函数。3. 回溯法。根据题意，选取度量标准，然后将可能的选择方法按度量标准所要求顺序排好，每次处理一个量，得到该意义下的最优解的分解处理。

## 图
无向图

1. 回路或环：第一个顶点和最后一个顶点相同的路径。
2. 简单回路或简单环：除第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路
3. 连通：顶点v至v’ 之间有路径存在4. 连通图：无向图图 G 的任意两点之间都是连通的，则称 G 是连通图。5. 连通分量：极大连通子图有向图：

1. 回路或环：第一个顶点和最后一个顶点相同的路径。2. 简单回路或简单环：除第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路。3. 连通：顶点v至v’之间有路径存在4. 强连通图：有向图G的任意两点之间都是连通的，则称G是强连通图。5. 强连通分量：极大连通子图1. 生成树：极小连通子图。包含图的所有n个结点，但只含图的n-1条边。在生成树中添加一条边之后，必定会形成回路或环。
2. 完  全  图：有 n(n-1)/2 条边的无向图。其中n是结点个数。3. 有向完全图：有 n(n-1)条边的有向图。其中n是结点个数。

### 图的存储形式
1. 邻接矩阵和加权邻接矩阵
	* 无权有向图：出度: i行之和；入度: j列之和。	* 无权无向图：i结点的度: i行或i列之和。
	* 加权邻接矩阵：相连为w，不相连为∞2. 邻接表
	* 用顶点数组表、边（弧）表表示该有向图或无向图
	* 顶点数组表：用数组存放所有的顶点。数组大小为图顶点数n
	* 边表（边结点表）：每条边用一个结点进行表示。同一个结点的所有的边形成它的边结点单链表。  ### 图的遍历
深度优先搜索利用栈，广度优先搜索利用队列

求一条从顶点i到顶点s的简单路径--深搜。求两个顶点之间的一条长度最短的路径--广搜。

### 生成树和最小生成树
每次遍历一个连通图将图的边分成遍历所经过的边和没有经过的边两部分，将遍历经过的边同图的顶点构成一个子图，该子图称为生成树。因此有DFS生成树和BFS生成树。

生成树是连通图的极小子图，有n个顶点的连通图的生成树必定有n-1条边,在生成树中任意增加一条边，必定产生回路。最小生成树：生成树中边的权值(代价)之和最小的树。

Kruskal算法：令最小生成树集合T初始状态为空，在有n个顶点的图中选取代价最小的边并从图中删去。若该边加到T中有回路则丢弃，否则留在T中；依此类推，直至T中有n-1条边为止。

Prim算法、Kruskal算法和Dijkstra算法均属于贪心算法。

### 双连通图和关节点
若从一个连通图中删去任何一个顶点及其相关联的边，它仍为一个连通图的话，则该连通图被称为**重（双）连通图**。若连通图中的某个顶点和其相关联的边被删去之后，该连通图被分割成两个或两个以上的连通分量，则称此顶点为**关节点**。

没有关节点的连通图为双连通图

1. 若生成树的根结点，有两个或两个以上的分支，则此顶点(生成树的根)必为关节点；
2. 对生成树上的任意一个非叶“顶点”，若其某棵子树中的所有“顶点”没有和其祖先相通的回边，则该“顶点”必为关节点。

### 有向无环图及其应用
拓扑排序

AOV网：用顶点表示活动，边表示活动的优先关系的有向图称为**AOV网**。AOV网中不允许有回路，这意味着某项活动以自己为先决条件。 

拓扑有序序列：把AOV网络中各顶点按照它们相互之间的优先关系排列一个线性序列的过程。若v<sub>i</sub>是v<sub>j</sub>前驱，则v<sub>i</sub>一定在v<sub>j</sub>之前；对于没有优先关系的点，顺序任意。拓扑排序：对AOV网络中顶点构造拓扑有序序列的过程。方法：

1. 在有向图中选一个没有前驱的顶点且输出之2. 从图中删除该顶点和所有以它为尾的弧3. 重复上述两步，直至全部顶点均已输出；或者当图中不存在无前驱的顶点为止(此时说明图中有环）

算法描述：

算法描述：
1. 把邻接表中入度为0的顶点依此进栈2. 若栈不空，则	* 栈顶元素v<sub>j</sub>退栈并输出；	* 在邻接表中查找v<sub>j</sub>的直接后继v<sub>k</sub>，把v<sub>k</sub>的入度减1；若v<sub>k</sub>的入度为0则进栈
3. 若栈空时输出的顶点个数不是n，则有向图有环；否则，拓扑排序完毕。

AOE网：带权的有向无环图，其中顶点表示事件，弧表示活动，权表示活动持续时间。在工程上常用来表示工程进度计划。一些定义：

1. 事件的最早发生时间（ve(j)）：从源点到j结点的最长的路径。意味着事件最早能够发生的时间。
2. 事件的最迟发生时间（vl(j)）：不影响工程的如期完工，事件j必须发生的时间。
3. 活动a<sub>i</sub>由弧<j,k>表示，持续时间记为 dut<j,k>,则有:
	* 活动的最早开始时间：e(i)=ve(j)
	* 活动的最迟开始时间：l(i)=vl(k) - dut(<j , k >)4. 活动余量：l(i)-e(i)的差
5. 关键活动：活动余量为0的活动
6. 关键路径：从源点到汇点的最长的一条路径，或者全部由关键活动构成的路径

## 查找
### 静态查找表
顺序表的顺序查找：应用范围：顺序表或线性链表表示的表，表内元素之间无序。查找过程：从表的一端开始逐个进行记录的关键字和给定值的比较。

顺序有序表的二分查找。平均查找时间(n+1)/n log<sub>2</sub>(n+1)

分块查找：将表分成几块，块内无序，块间有序；先确定待查记录所在块，再在块内查找。

1. 用数组存放待查记录,2. 建立索引表，由每块中最大（小）的关键字及所属块位置的信息组成。
3. 当索引表较大时，可以采用二分查找4. 在数据量极大时，索引可能很多，可考虑建立索引表的索引，即二级索引，原则上索引不超过三级

分块查找平均查找长度：*ASL*<sub>*bs*</sub> = *L*<sub>*b*</sub> + *L*<sub>*w*</sub>。其中，*L*<sub>*b*</sub>是查找索引表确定所在块的平均查找长度， *L*<sub>*w*</sub>是在块中查找元素的平均查找长度。在n一定时，可以通过选择s使ASL尽可能小。当s=sqrt(n)时，ASL最小。1. 时间：顺序查找最差，二分最好，分块介于两者之间2. 空间：分块最大，需要增加索引数据的空间
3. 顺序查找对表没有特殊要求  4. 分块时数据块之间在物理上可不连续。所以可以达到插入、删除数据只涉及对应的块；另外，增加了索引的维护。5. 二分查找要求表有序，所以若表的元素的插入与删除很频繁，维持表有序的工作量极大。6. 在表不大时，一般直接使用顺序查找。## 动态查找
二叉排序树的结点删除：

1. x为叶子结点，则直接删除2. x只有左子树x<sub>L</sub>或只有右子树x<sub>R</sub> ,则令x<sub>L</sub>或x<sub>R</sub>直接成为双亲结点f的子树； 
3. x即有左子树x<sub>L</sub>也有右子树x<sub>R</sub>，在x<sub>L</sub>中选值最大的代替x，该数据按二叉排序树的性质应在最右边。平衡二叉树：每个结点的平衡因子都为 1、－1、0 的二叉排序树。或者说每个结点的左右子树的高度最多差1的二叉排序树。平衡二叉树的平衡：

1. 左调整(新结点插入在左子树上的调整)：
	* LL(插入在结点左子树的左子树上)：旋转前后高度都为h+1
	* LR(新插入结点在左子树的右子树上)：旋转前后高度仍为h+1
2. 右调整(新结点插入在右子树上进行的调整):
	* RR(插入在的右子树的右子树上)：处理方法和 LL对称
	* RL(插入在的右子树的左子树上)：处理方法和 LR对称

平衡树建立方法：

1. 按二叉排序树插入结点2. 如引起结点平衡因子变为|2|，则确定旋转点，该点是离根最远（或最接近于叶子的点）3. 确定平衡类型后进行平衡处理，平衡后以平衡点为根的子树高不变## B_树的B+树### B_树
B-树就是B树。m阶B_树满足或空，或为满足下列性质的m叉树：

![B-树](http://hi.csdn.net/attachment/201106/7/8394323_13074405906V6Q.jpg)

1. 树中每个结点最多有m棵子树2. 根结点在不是叶子时，至少有两棵子树3. 除根外，所有非终端结点至少有⎡m/2⎤棵子树 4. 有s个子树的非叶结点具有 n = s-1个关键字，结点的信息组织为:(n,A<sub>0</sub>,K<sub>1</sub>,A<sub>1</sub>,K<sub>2</sub>,A<sub>2</sub> … K<sub>n</sub>，A<sub>n</sub>)。这里：n为关键字的个数，k<sub>i</sub>（i=1,2,…,n)为关键字，且满足K<sub>i</sub>小于K<sub>i+1</sub>,，A<sub>i</sub>(i=0,1,..n)为指向子树的指针。5. 所有的叶子结点都出现在同一层上，不带信息（可认为外部结点或失败结点）。
6. 关键字集合分布在整颗树中；
7. 任何一个关键字出现且只出现在一个结点中
8. 搜索有可能在非叶子结点结束
9. 其搜索性能等价于在关键字全集内做一次二分查找B_树中结点的插入

1. m代表B_树的阶，插入总发生在最低层2. 插入后关键字个数小于等于 m-1,完成。3. 插入后关键字个数等于m,结点分裂，以中点数据为界一分为二，中点数据放到双亲结点中。这样就有可能使得双亲结点的数据个数为m,引起双亲结点的分裂，最坏情况下一直波及到根，引起根的分裂——B_树长高。

3阶`B_`树的插入。每个结点最多3棵子树，2个数据；最少2棵子树，1个数据。所以3阶B_树也称为2-3树。

B_树中结点的删除

1. 删除发生在最底层	* 被删关键字所在结点中的关键字数目大于等于 m/2 ，直接删除。
	* 删除后结点中数据为⎡m/2⎤-2，而相邻的左（右）兄弟中数据大于⎡m/2⎤-1，此时左（右兄弟）中最大（小）的数据上移到双亲中，双亲中接（靠）在它后（前）面的数据移到被删数据的结点中
	* 其左右兄弟结点中数据都是⎡m/2⎤-1，此时和左（右）兄弟合并，合并时连同双亲中相关的关键字。此时，双亲中少了一项，因此又可能引起双亲的合并，最坏一直到根，使B-树降低一层。
2. 删除不在最底层
	* 在大于被删数据中选最小的代替被删数据，问题转换成在最底层的删除### B+树
在实际的文件系统中，用的是B+树或其变形。有关性质与操作类似与B_树。![B+树](http://hi.csdn.net/attachment/201106/7/8394323_1307440587b6WG.jpg)差异：1. 有n棵子树的结点中有n个关键字，每个关键字不保存数据，只用来索引，所有数据都保存在叶子节点。2. 所有叶子结点中包含全部关键字信息，及对应记录位置信息及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。(而B树的叶子节点并没有包括全部需要查找的信息)
3. 所有非叶子为索引，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B树的非终节点也包含需要查找的有效信息)4. 非叶最底层顺序联结，这样可以进行顺序查找

B+特性

1. 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；
2. 不可能在非叶子结点命中
3. 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层
4. 更适合文件索引系统查找过程

* 在 B+ 树上，既可以进行缩小范围的查找，也可以进行顺序查找；* 在进行缩小范围的查找时，不管成功与否，都必须查到叶子结点才能结束；* 若在结点内查找时，给定值≤K<sub>i</sub>， 则应继续在 A<sub>i</sub> 所指子树中进行查找插入和删除的操作：类似于B_树进行，即必要时，也需要进行结点的“分裂”或“合并”。为什么说B+tree比B树更适合实际应用中操作系统的文件索引和数据库索引？

1. B+tree的磁盘读写代价更低
	* B+tree的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
	* 举个例子，假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B-tree(一个结点最多8个关键字)的内部结点需要2个盘快。而B+树内部结点只需要1个盘快。当需要把内部结点读入内存中的时候，B树就比B+树多一次盘块查找时间(在磁盘中就是盘片旋转的时间)。
2. B+tree的查询效率更加稳定
 * 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。## 哈希表
1. 在记录的存储地址和它的关键字之间建立一个确定的对应关系；这样不经过比较，一次存取就能得到元素。 
2. 哈希函数——在记录的关键字与记录的存储位置之间建立的一种对应关系。是从关键字空间到存储位置空间的一种映象。
3. 哈希表——应用哈希函数，由记录的关键字确定记录在表中的位置信息，并将记录根据此信息放入表中，这样构成的表叫哈希表。
4. Hash查找适合于关键字可能出现的值的集合远远大于实际关键字集合的情形。

根据抽屉原理，冲突是不可能完全避免的，所以，要解决：1. 构造一个性能好，冲突少的Hash函数2. 如何解决冲突常用的哈希函数

1. 直接定址法。仅适合于：地址集合的大小 == 关键字集合的大小2. 数字分析法。对关键字进行分析，取关键字的若干位或其组合作哈希地址。仅适合于：能预先估计出全体关键字的每一位上各种数字出现的频度。
3. 平方取中法。以关键字的平方值的中间几位作为存储地址。
4. 折叠法。将关键字分割成位数相同的几部分，然后取这几部分的叠加和（舍去进位）做哈希地址。移位叠加/间界叠加。适合于: 关键字的数字位数特别多，且每一位上数字分布大致均匀情况。
5. 除留余数法。取关键字被某个不大于哈希表表长m的数p除后所得余数作哈希地址，即H(key)=key%p，p<=m。
6. 随机数法。取关键字的伪随机函数值作哈希地址，即H(key)=random(key)，适于关键字长度不等的情况。

冲突解决

1. 开放定址法。当冲突发生时，形成一个探查序列；沿此序列逐个地址探查，直到找到一个空位置（开放的地址），将发生冲突的记录放到该地址中。即H<sub>i</sub>=(H(key)+d<sub>i</sub>) % m，i=1,2,……k(k<=m-1)，H(key)哈希函数，m哈希表长，d<sub>i</sub>增量序列。缺点：删除：只能作标记，不能真正删除；溢出；聚集问题
	* 线性探测再散列：d<sub>i</sub>=1，2，3，...，m-1
	* 二次探测再散列：d<sub>i</sub>=1<sup>2</sup>,-1<sup>2</sup>,2<sup>2</sup>,-2<sup>2</sup>,...，±k<sup>2</sup>（k<=m/2）
	* 伪随机探测再散列: d<sub>i</sub>为伪随机数序列
2. 链地址法：将所有关键字为同义词的记录存储在一个单链表中，并用一维数组存放头指针。

Hash查找效率：装填因子=表中记录数/表容量

## 内部排序
1. 内部排序：全部数据可同时放入内存进行的排序。    2. 外部排序：文件中数据太多，无法全部调入内存进行的排序。插入类：

1. 直接插入排序。最坏情况是数据递减序，数据比较和移动量最大，达到O(n<sup>2</sup>)，最好是数据是递增序，比较和移动最少为O(n)
2. 折半插入排序 。由于插入第i个元素到r[1]到r[i-1]之间时，前i个数据是有序的，所以可以用折半查找确定插入位置，然后插入。
3. 希尔排序。缩小增量排序。5-3-1。在实际应用中，步长的选取可简化为开始为表长n的一半（n/2），以后每次减半，最后为1。

交换类：

1. 冒泡排序。O(n<sup>2</sup>)通常认为冒泡是比较差的，可以加些改进，比如在一趟中无数据的交换，则结束等措施。
	* 在数据已基本有序时，冒泡是一个较好的方法   * 在数据量较少时（15个左右）可以用冒泡
2. 快速排序。
	* 时间复杂度。最好情况：每次支点总在中间，O(nlog<sub>2</sub>n)，平均O(nlog<sub>2</sub>n)。最坏，数据已是递增或递减，O(n<sup>2</sup>)。
	* 空间复杂度。需栈空间以实现递归，最坏情况：S(n)=O(n)；一般情况：S(n)=O(log<sub>2</sub>n)
	* 在序列已是有序的情况下，时间复杂度最高。原因：支点选择不当。改进：随机选取支点或最左、最右、中间三个元素中的值处于中间的作为支点，通常可以避免最坏情况。所以，快速排序在表已基本有序的情况下不合适。	* 在序列长度已较短时，采用直接插入排序、起泡排序等排序方法。序列的个数通常取10左右。

选择类排序：

1. 简单选择排序。O(n<sup>2</sup>)。总比较次数n(n-1)/2。
2. 堆排序。建堆 O(n)，筛选O(nlogn)
3. 归并排序。时间：与表长成正比，若一个表表长是m，另一个是n，则时间是O(m+n)。单独一个数组归并，时间：O(nlogn)，空间：O(n)。
4. 基数排序。在一般情况下，每个结点有 d 位关键字，必须执行 t = d次分配和收集操作。分配的代价：O(n)；收集的代价：O(rd) （rd是基数）；总的代价为：O( d ×(n + rd))。比较法分类的下界：O(nlogn)## 外部排序1. 生成合并段（run）：读入文件的部分记录到内存－>在内存中进行内部排序－>将排好序的这些记录写入外存，形成合并段－>再读入该文件的下面的记录，往复进行，直至文件中的记录全部形成合并段为止。
2. 外部合并：将上一阶段生成的合并段调入内存，进行合并，直至最后形成一个有序的文件。1. 根据内存容量设若干个输入缓冲区和一个输出缓冲区。若采用二路归并，用两个输入缓冲。
2. 归并的方法类似于归并排序的归并算法。增加的是对缓冲的监视，对于输入，一旦缓冲空，要到相应文件读后续数据，对于输出缓冲，一旦缓冲满，要将缓冲内容写到文件中去。## 有效的算法设计
1. 贪心法。Dijkstra的最短路径、Prim求最小生成树的O(n<sub>2</sub>)的算法、关键路径及关键活动的求法。2. 回溯法3. 分支限界法4. 分治法。分割、求解、合并。二分查找、归并排序、快速排序。5. 动态规划动态规划解题的方法是一种高效率的方法，其时间复杂度通常为O(n<sub>2</sub>)，O(n<sub>3</sub>)等，可以解决相当大的信息量。（数塔在n<=100层时，可以在很短的时间内得到问题解）* 适用的原则：原则为优化原则，即整体优化可以分解为若干个局部优化。* 动态规划比穷举法具有较少的计算次数* 递归算法需要很大的栈空间，而动态规划不需要栈空间贪心和动态规划的差别：1. 所谓贪心选择性质是指所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到。这是贪心算法可行的第一个基本要素，也是贪心算法与动态规划算法的主要区别。2. 在动态规划算法中，每步所作的选择往往依赖于相关子问题的解。因而只有在解出相关子问题后，才能作出选择。而在贪心算法中，仅在当前状态下作出最好选择，即局部最优选择。然后再去解作出这个选择后产生的相应的子问题。
3. 贪心算法所作的贪心选择可以依赖于以往所作过的选择，但决不依赖于将来所作的选择，也不依赖于子问题的解。正是由于这种差别，动态规划算法通常以自底向上的方式解各子问题，而贪心算法则通常以自顶向下的方式进行,以迭代的方式作出相继的贪心选择，每作一次贪心选择就将所求问题简化为一个规模更小的子问题。 1. P问题，如果它可以通过运行多项式次(即运行时间至多是输入量大小的多项式函数的一种算法获得解决）。----确定性问题2. NP 问题，虽然可以用计算机求解，但是对于任意常数k，它们不能在O(n<sup>k</sup>)时间内得到解答，可以在多项式时间内验证出来。
3. NP完全问题，知道有效的非确定性算法，但是不知道是否存在有效的确定性算法，同时，不能证明这些问题中的任何一个不存在有效的确定性算法。这类问题称为NP完全问题。